# TODO List

## üìä Current Status (2026-01-25)

**Test Set Performance (689 images):**
- **YOLO12n (BEST): 0.7081 mAP50** üèÜ ‚úÖ
- Our YOLOv11n baseline: **0.7065 mAP50** ‚úÖ
- UBM production model: **0.6655 mAP50**
- Gabriele's unverified claim: **0.824 mAP50** ‚ö†Ô∏è

**Improvements Over UBM Production:**
- YOLO12n: **+6.4%** (0.7081 vs 0.6655)
- Our baseline: **+6.2%** (0.7065 vs 0.6655)

**Training Status:**
- ‚úÖ YOLOv11n baseline complete
- ‚úÖ Hyperparameter sweep complete (stopped - no improvement)
- ‚úÖ YOLO12n training complete (300/300 epochs)
- ‚úÖ Test set evaluation complete

**Next Immediate Action:** INT8 optimization ‚Üí `python3 optimize_yolo12_int8.py`

**Timeline:** 30 min INT8 export + benchmarking, then deployment to RTX 4060

---

## ‚úÖ COMPLETED

### 1. ‚úÖ Download Correct Dataset
Downloaded `FSOCO-12` from `fmdv/fsoco-kxq3s` version 12 ‚Üí `datasets/FSOCO-12/`

### 2. ‚úÖ Modify `train_baseline.py` to Accept Dataset Argument
Script now accepts `--data`, `--epochs`, `--batch` arguments. Default: FSOCO-12.

### 3. ‚úÖ Restart Baseline Training with Correct Dataset
**Currently running:** `python train_baseline.py` with FSOCO-12 dataset
- Log: `training_FSOCO_baseline.log`
- Expected completion: ~12 hours
- Target: mAP50 ‚âà 0.824

---

### 4. ‚úÖ Baseline Training Completed
**Validation Set Result:** mAP50 = 0.714 (Precision: 0.832, Recall: 0.657)
**Test Set Result:** mAP50 = 0.707 (Precision: 0.816, Recall: 0.662)
- 14.3% gap to Gabriele's test set baseline (0.824)
- Analysis: `BASELINE_RESULTS_ANALYSIS.md`
- Our baseline BEATS UBM production by 6.2% on test set

---

## Next Steps - Decision Required

### ‚úÖ Decision Made: Option A - Hyperparameter Search

## üîç Critical Updates (2026-01-24)

### From Edoardo
1. **Thesis results (mAP50 = 0.824) came from Gabriele & Patta's training**, not Edo's own work
2. **They used a "particular dataset"** - exact details unknown to Edo
3. **Image brightness is a major problem** for cone type classification
4. **Orange cone size distinction** (normal vs large) is difficult at distance
5. **Real validation should be on car data**, not internet datasets like FSOCO

### From Gabriele's CV Report (Nov 2025) - üî¥ GAME CHANGER

**CRITICAL DISCOVERY: Dataset Split Mismatch!**

Gabriele's report reveals the **TRUE baseline** from their production system:

| Metric | Gabriele's Baseline | Dataset Split |
|--------|---------------------|---------------|
| **mAP50** | **0.824** | **Test set (689 images)** ‚úÖ |
| Precision | 0.849 | Test set |
| Recall | 0.765 | Test set |
| mAP50-95 | 0.570 | Test set |

**‚úÖ OUR TEST SET EVALUATIONS (COMPLETED 2026-01-25):**

| Model | mAP50 (Validation) | mAP50 (Test) | Gap from Gabriele |
|-------|-------------------|--------------|-------------------|
| Our baseline | 0.714 | **0.707** | -14.3% |
| UBM production | 0.670 | **0.666** | -19.2% |
| Gabriele's baseline | ‚Äî | **0.824** | ‚Äî |

**‚úÖ Key Findings:**
- Our baseline on test: **0.7065 mAP50** (beats UBM by 6.2%)
- 14.3% gap to close to reach Gabriele's baseline
- Test set slightly harder than validation (1% drop)
- YOLO12 training is next step to close gap

**Inference performance (RTX 3080 Mobile + TensorRT):**
- Total pipeline: 9.46 ms (with ORB features)
- YOLO inference only: 6.78 ms
- Real-time capable at 60 fps

**See:** `GABRIELE_BASELINE_ANALYSIS.md` for full details

---

## Current Plan: YOLO12 Training (Branch A)

### ‚úÖ Phase 1: Hyperparameter Sweep - STOPPED (2026-01-25)

**Results:** 10/21 runs completed, 61.9% crash rate
- **Best run:** 0.7088 mAP50 (WORSE than baseline 0.7140)
- **Mean of 10 runs:** 0.7030 mAP50
- **Conclusion:** Model performance agnostic to hyperparameters - Ultralytics defaults already near-optimal
- **Crash cause:** High mixup (>0.15) + high dropout (>0.12) = training instability

**See:** `SWEEP_CRASH_INVESTIGATION.md` and `SWEEP_ANALYSIS.md` for full analysis

**Decision:** Pivot to architectural improvements (YOLO12) instead of hyperparameter tuning

### ‚úÖ Phase 2: Test Set Evaluation - COMPLETED (2026-01-25)

**üéØ CRITICAL RESULTS - Test Set Performance (689 images)**

| Model | mAP50 | mAP50-95 | Precision | Recall | Gap from Gabriele |
|-------|-------|----------|-----------|--------|-------------------|
| **Gabriele's baseline** (CV report) | **0.824** | 0.570 | 0.849 | 0.765 | ‚Äî |
| **Our baseline** | **0.7065** | 0.4898 | 0.8164 | 0.6616 | **-0.1175 (-14.3%)** |
| **UBM production** | **0.6655** | 0.4613 | 0.8031 | 0.5786 | -0.1585 (-19.2%) |

**Key Findings:**
1. ‚úÖ **Our baseline BEATS UBM production by 6.2%** (0.7065 vs 0.6655)
2. ‚ö†Ô∏è **14.3% gap to Gabriele's baseline** (0.1175 mAP50 to close)
3. ‚úÖ Test set slightly harder than validation (our baseline: 0.714 val ‚Üí 0.707 test, 1% drop)
4. ‚ö†Ô∏è NEITHER model achieves Gabriele's 0.824 on test set

**Evaluation Commands Run:**
```bash
python3 evaluate_baseline_test.py    # Our baseline on test
python3 evaluate_ubm_model.py         # UBM production on test
```

**Next Target:** Train YOLO12n to close 14.3% gap (target mAP50 ‚â• 0.82)

### ‚úÖ Phase 3: Train YOLO12n (Branch A) - COMPLETED (2026-01-25)

**Goal:** Close gap to proven baseline using 2025 state-of-the-art architecture

**Results:**
- Training time: 2.5 days (300 epochs, RTX 4080 Super)
- **Test mAP50: 0.7081** ‚úÖ
- **vs Our baseline: +0.2%** (0.7081 vs 0.7065)
- **vs UBM production: +6.4%** (0.7081 vs 0.6655)
- Inference: 4.1 ms on RTX 4080 Super

**YOLO12 Key Features:**
- Area Attention Mechanism (efficient self-attention)
- R-ELAN (Residual Efficient Layer Aggregation)
- FlashAttention integration

**Per-Class Performance (Test Set):**
```
Class              Precision   Recall    mAP50
blue_cone          0.912       0.738     0.804
large_orange_cone  0.912       0.821     0.871  ‚≠ê Best class
orange_cone        0.879       0.722     0.775
yellow_cone        0.890       0.727     0.796
unknown_cone       0.607       0.264     0.295  ‚ö†Ô∏è Challenging
```

**Decision:** ‚úÖ **SUCCESS** - Proceed to INT8 optimization (Branch A)

### ‚úÖ Phase 4: Evaluate YOLO12 on Test Set - COMPLETED

**Results:**
```bash
python3 evaluate_yolo12_test.py  # ‚úÖ COMPLETED
```

**Test Set Performance (689 images):**
- **YOLO12n: 0.7081 mAP50** ‚úÖ
- Our YOLOv11n baseline: 0.7065 mAP50
- UBM production: 0.6655 mAP50

**Comparison to Proven Baselines:**
- vs UBM production: **+6.4%** (0.0426 mAP50 improvement)
- vs Our baseline: **+0.2%** (0.0016 mAP50 improvement)

**Success Criteria:** ‚úÖ **MET** - Beats proven UBM baseline by 6.4%

**Log:** `yolo12_test_evaluation.log`

### üöÄ Phase 5: INT8 Optimization & Benchmarking (30 minutes) - NEXT STEP

**YOLO12 Training Complete:** ‚úÖ Achieved 0.7081 mAP50 on test set (+6.4% vs UBM)

**Current Status:** Ready for INT8 optimization (Branch A)

**Deployment Target:**
- Hardware: RTX 4060 (on car)
- Baseline: 6.78ms inference (Gabriele, RTX 3080 Mobile, TensorRT FP16)
- Target: < 2.5ms on RTX 4060 (2.7√ó speedup minimum)

**INT8 Optimization Commands:**

**Option 1: Complete Pipeline (Recommended)**
```bash
python3 optimize_yolo12_int8.py
```

**Option 2: Step-by-Step**
```bash
# Step 1: Export to ONNX (optional)
python3 export_yolo12_onnx.py

# Step 2: Export to TensorRT INT8
# ‚ö†Ô∏è Uses VALIDATION SET for calibration, NOT test set!
python3 export_tensorrt_int8.py

# Step 3: Benchmark speed and accuracy
python3 benchmark_int8.py
```

**What INT8 Does:**
1. Evaluates FP32 baseline accuracy (validation set)
2. Exports to TensorRT INT8 (uses ~500 validation images for calibration)
3. Evaluates INT8 accuracy (validation set)
4. Benchmarks inference speed (100 runs)

**Expected Results:**
- Speed: 1.5-2.0√ó faster (~2.0-2.7 ms on RTX 4080 Super)
- Accuracy: <1% loss (0.7081 ‚Üí ~0.702-0.706 mAP50)
- Size: 3.5√ó smaller (5.3 MB ‚Üí 1.5 MB)
- **RTX 4060:** ~1.7-2.2 ms (3-4√ó faster than baseline!)

**Critical Notes:**
- ‚ö†Ô∏è Calibration uses VALIDATION SET only (NEVER test set!)
- ‚ö†Ô∏è Baseline (6.78ms) is ALREADY TensorRT FP16 optimized
- ‚úÖ RTX 4060 has INT8 Tensor Cores (242 INT8 TOPS)

**See:** `INT8_OPTIMIZATION_GUIDE.md` for complete documentation

**Deliverables:**
- INT8 TensorRT engine (`best.engine`)
- Speed benchmark report (FP32 vs INT8)
- Accuracy comparison (validation set)
- Deployment recommendations for RTX 4060

### Files Created

**Test Set Evaluation:**
- ‚úÖ `evaluate_baseline_test.py` - Evaluate our baseline on test set
- ‚úÖ `evaluate_ubm_model.py` - Evaluate UBM production on test set
- ‚úÖ `evaluate_yolo12_test.py` - Evaluate YOLO12 on test set
- ‚úÖ `yolo12_test_evaluation.log` - YOLO12 test results log

**YOLO12 Training (Branch A):**
- ‚úÖ `train_yolo12.py` - Train YOLO12n (300 epochs, attention-centric architecture)
- ‚úÖ `TWO_BRANCH_STRATEGY.md` - Complete implementation plan with decision tree
- ‚úÖ `NEXT_STEPS_COMMANDS.md` - Command reference guide

**INT8 Optimization (Next Step):**
- ‚úÖ `export_yolo12_onnx.py` - Export YOLO12 to ONNX format
- ‚úÖ `export_tensorrt_int8.py` - Export to TensorRT INT8 engine
- ‚úÖ `benchmark_int8.py` - Benchmark FP32 vs INT8 speed/accuracy
- ‚úÖ `optimize_yolo12_int8.py` - Complete INT8 pipeline (all steps)
- ‚úÖ `INT8_OPTIMIZATION_GUIDE.md` - Complete INT8 documentation

**Hyperparameter Sweep (Stopped):**
- ‚úÖ `sweep_config.yaml` - Search space definition (13 hyperparameters)
- ‚úÖ `train_sweep.py` - Training script for sweep
- ‚úÖ `launch_sweep.sh` - One-command sweep launcher
- ‚úÖ `analyze_sweep.py` - Extract best config from sweep results
- ‚úÖ `SWEEP_CRASH_INVESTIGATION.md` - Why 61.9% of runs crashed (high mixup + dropout)
- ‚úÖ `SWEEP_ANALYSIS.md` - Complete sweep results analysis

**Baseline Analysis:**
- ‚úÖ `GABRIELE_BASELINE_ANALYSIS.md` - Ground truth from CV report (0.824 unverified)
- ‚úÖ `BASELINE_RESULTS_ANALYSIS.md` - Our baseline analysis
- ‚úÖ `UBM_MODEL_INFO.md` - UBM production model evaluation & comparison tables

**Utilities:**
- ‚úÖ `wandb_api.py` - W&B API interface (fixed import shadowing)
- ‚úÖ `benchmark_inference.py` - ONNX/TensorRT inference speed benchmarking
- ‚úÖ `RESEARCH_FOCUS_AREAS.md` - Brightness & orange cone challenges

---

## Future Improvements

### 4. Model Experiments (Week 1-2)
After baseline is confirmed:
- Train YOLOv11s/m variants
- Test RT-DETR
- Experiment with image size (640 ‚Üí 800/1024)
- Try different augmentations

### 5. Optimization (Week 2)
- ONNX export
- TensorRT conversion for RTX 4060
- Inference speed benchmarking

### 6. Report & Documentation
- Benchmark comparison table
- W&B run comparisons
- Final project report
