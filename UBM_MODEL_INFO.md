# UBM Official Model Information

## Source

**From:** Gabriele (UBM Driverless team member)
**Date:** 2026-01-24

## Model Details

### YOLOv11n (640p, 300 epochs)
**Location:** `/home/nicolas/Github/ubm-yolo-detector/yolo/models/yolov11n_640p_300ep/best.pt`

**Training:**
- Dataset: https://www.fsoco-dataset.com/
- Resolution: 640x640
- Epochs: 300
- Model: YOLOv11n
- Status: "Working well on detecting cones" on actual car

**Files:**
- `best.pt` (5.3 MB) - PyTorch weights
- `best.onnx` (11 MB) - ONNX format
- `best_openvino_model/` - OpenVINO FP32 format

**Classes:**
```python
{
  0: 'blue_cone',
  1: 'large_orange_cone',
  2: 'orange_cone',
  3: 'unknown_cone',
  4: 'yellow_cone'
}
```

### YOLOv12n (1280p, 300 epochs)
**Location:** `/home/nicolas/Github/ubm-yolo-detector/yolo/models/yolov12n_1280p_300ep/best.pt`

**Training:**
- Dataset: Likely same FSOCO
- Resolution: 1280x1280 (higher resolution)
- Epochs: 300
- Model: YOLOv12n (newer architecture)

---

## Deployment on Car

**From:** https://github.com/ubm-driverless/ubm-fsae/tree/main/zed2_driver

### Production Model (INT8 Quantized)
**Location:** `ubm-fsae/zed2_driver/yolo/models/best_int8_openvino_model/`

**Format:** OpenVINO INT8 (quantized for speed)
- Faster inference on embedded hardware
- Reduced precision (INT8 vs FP32)
- Trade-off: Speed vs slight accuracy loss

**Hardware:** ASU (Autonomous System Unit) with NVIDIA RTX 4060

---

## ‚úÖ Evaluation Results - FSOCO-12 Test Set (689 images)

**Evaluation Date:** 2026-01-25

### UBM Production Model Performance

**Model:** `/home/nicolas/Github/ubm-yolo-detector/yolo/models/yolov11n_640p_300ep/best.pt`

**Test Set Results:**
```
mAP50:     0.6655
mAP50-95:  0.4613
Precision: 0.8031
Recall:    0.5786
```

**Analysis:** **Scenario C occurred** - Domain mismatch confirmed!
- UBM production model scored **0.6655 mAP50** on FSOCO-12 test set
- This is **19.2% below** Gabriele's claimed 0.824 baseline
- Validates Edo's comment about using a "particular dataset"
- UBM's training data ‚â† FSOCO-12

---

## üìä Comparison to Our Models

### Test Set Performance (689 images)

| Model | mAP50 | mAP50-95 | Precision | Recall | vs UBM | vs Our Baseline |
|-------|-------|----------|-----------|--------|--------|-----------------|
| **UBM Production** | 0.6655 | 0.4613 | 0.8031 | 0.5786 | ‚Äî | ‚Äî |
| **Our YOLOv11n Baseline** | 0.7065 | 0.4898 | 0.8164 | 0.6616 | **+6.2%** ‚úÖ | ‚Äî |
| **YOLO12n** | **0.7081** | 0.4846 | 0.8401 | 0.6542 | **+6.4%** ‚úÖ | **+0.2%** ‚úÖ |

### Key Findings

1. ‚úÖ **Our YOLOv11n baseline BEATS UBM production by 6.2%** (0.7065 vs 0.6655)
2. ‚úÖ **YOLO12n is BEST model: 0.7081 mAP50** (test set) - beats both baselines
3. ‚úÖ **YOLO12n improves over UBM by 6.4%** (0.7081 vs 0.6655)
4. ‚ö†Ô∏è **Gabriele's 0.824 claim is UNVERIFIED** - UBM production can't reproduce it
5. ‚úÖ **Proven baseline: 0.6655** (actual car model on FSOCO-12 test)

---

## ‚úÖ YOLO12 Results - TRAINING COMPLETE

**Training Status:** ‚úÖ Completed (300/300 epochs)

**Test Set Performance (689 images):**
- **mAP50: 0.7081** (+0.2% vs our YOLOv11n baseline, +6.4% vs UBM)
- mAP50-95: 0.4846
- Precision: 0.8401
- Recall: 0.6542
- Inference: 4.1 ms (RTX 4080 Super)

**Per-Class Performance (Test Set):**
```
Class              Precision   Recall    mAP50    mAP50-95
blue_cone          0.912       0.738     0.804    0.548
large_orange_cone  0.912       0.821     0.871    0.693
orange_cone        0.879       0.722     0.775    0.525
yellow_cone        0.890       0.727     0.796    0.534
unknown_cone       0.607       0.264     0.295    0.124  ‚ö†Ô∏è (challenging)
```

**vs UBM Production:** +6.4% improvement (0.7081 vs 0.6655)

**Decision:** YOLO12 is **SUCCESSFUL** - beats proven baseline!

---

## üìà Success Criteria (Revised)

**Original (unverified):** Beat Gabriele's claimed 0.824 mAP50
**Revised (proven):** Beat UBM production 0.6655 mAP50

| Target | Status |
|--------|--------|
| Beat UBM production (0.6655) | ‚úÖ **ACHIEVED** (+6.2% with baseline) |
| Beat our baseline (0.7065) | üîÑ **In progress** (YOLO12 at +0.9% on val) |
| Inference < 2ms on RTX 4060 | üîÑ **Pending** (INT8 quantization) |

---

## üöÄ Next Steps - INT8 Optimization

### Phase 1: INT8 Export and Benchmarking (30 minutes)

**YOLO12 achieved 0.7081 mAP50 on test set - proceed with INT8 optimization!**

**Complete Pipeline (One Command):**
```bash
python3 optimize_yolo12_int8.py
```

**Or step-by-step:**
```bash
# Step 1: Export to ONNX (optional)
python3 export_yolo12_onnx.py

# Step 2: Export to TensorRT INT8 (uses validation set for calibration)
python3 export_tensorrt_int8.py

# Step 3: Benchmark speed and accuracy
python3 benchmark_int8.py
```

**Expected Results:**
- Speed: 1.5-2.0√ó faster (~2.0-2.7 ms on RTX 4080 Super)
- Accuracy: <1% loss (0.7081 ‚Üí ~0.702-0.706)
- Size: 3.5√ó smaller (5.3 MB ‚Üí 1.5 MB)

### Phase 2: Deployment to RTX 4060

1. Transfer `best.engine` to car's ASU
2. Integrate into ROS2 pipeline
3. Real-world testing on track

**Expected RTX 4060 Performance:**
- INT8: ~1.7-2.2 ms per image
- **vs Baseline (6.78 ms):** **3-4√ó FASTER!** üöÄ

---

## Related Files

- `evaluate_ubm_model.py` - UBM test set evaluation script
- `evaluate_baseline_test.py` - Our baseline test set evaluation
- `evaluate_yolo12_test.py` - YOLO12 test set evaluation (pending)
- `ubm_evaluation.log` - UBM evaluation log

---

**Date:** 2026-01-25
**Status:** ‚úÖ **YOLO12 Training Complete** | ‚úÖ **Test Set Evaluation Complete** | üöÄ **Ready for INT8 Optimization**
